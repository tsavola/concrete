/*
 * Copyright (c) 2011, 2012  Timo Savola
 *
 * This library is free software; you can redistribute it and/or
 * modify it under the terms of the GNU Lesser General Public
 * License as published by the Free Software Foundation; either
 * version 2.1 of the License, or (at your option) any later version.
 */

#include "arena.hpp"

#include <concrete/context.hpp>
#include <concrete/util/assert.hpp>
#include <concrete/util/backtrace.hpp>
#include <concrete/util/trace.hpp>

namespace concrete {

ArenaAccess::ArenaAccess(const ArenaAccess &other) throw ():
	m_version(other.m_version),
	m_data(other.m_data)
{
}

void ArenaAccess::operator=(const ArenaAccess &other) throw ()
{
	m_version = other.m_version;
	m_data = other.m_data;
}

void *ArenaAccess::arena_access(unsigned int address, size_t minimum_size) const
{
	Arena &arena = Arena::Active();

	if (m_version != arena.version()) {
		auto accession = arena.access(address, minimum_size);

		m_version = accession.version;
		m_data = accession.data;
	}

	return m_data;
}

void *ArenaAccess::nonthrowing_arena_access(unsigned int address, size_t minimum_size) const throw ()
{
	Arena &arena = Arena::Active();

	if (m_version != arena.version()) {
		auto accession = arena.nonthrowing_access(address, minimum_size);
		if (accession.data == NULL)
			return NULL;

		m_version = accession.version;
		m_data = accession.data;
	}

	return m_data;
}

Arena &Arena::Active() throw ()
{
	return Context::Active().arena();
}

const Arena::Header *Arena::AllocationHeader(const void *data) throw ()
{
	return reinterpret_cast<const Header *> (data) - 1;
}

Arena::Header *Arena::AllocationHeader(void *data) throw ()
{
	return reinterpret_cast<Header *> (data) - 1;
}

size_t Arena::AllocationSize(const void *data) throw ()
{
	return AllocationHeader(data)->size;
}

Arena::Arena() throw ():
	m_allocator(Arena::SizeLimit),
	m_version(1),
	m_access_error_address(0)
{
}

Arena::Arena(void *base, size_t size):
	m_allocator(base, size, Arena::SizeLimit),
	m_version(1),
	m_access_error_address(0)
{
}

Arena::Snapshot Arena::snapshot() const throw ()
{
	return Snapshot(m_allocator.arena_base, m_allocator.arena_size);
}

Arena::Allocation Arena::allocate(size_t size)
{
	check_access_error();

	void *old_arena_base = m_allocator.arena_base;

	size_t full_size = sizeof (Header) + size;
	if (full_size < size)
		throw AllocationError(size);

	auto alloc = m_allocator.allocate(full_size);
	if (alloc.data == NULL)
		throw AllocationError(size);

	if (m_allocator.arena_base != old_arena_base)
		update_version();

	new (alloc.data) Header(size);

	alloc.address += sizeof (Header);
	alloc.data = reinterpret_cast<void *> (reinterpret_cast<char *> (alloc.data) + sizeof (Header));

	return alloc;
}

void Arena::free(unsigned int address, void *data) throw ()
{
	void *old_arena_base = m_allocator.arena_base;

	size_t  alloc_addr = address - sizeof (Header);
	void   *alloc_data = reinterpret_cast<void *> (reinterpret_cast<char *> (data) - sizeof (Header));
	size_t  alloc_size = AllocationSize(data) + sizeof (Header);

	m_allocator.free(alloc_addr, alloc_data, alloc_size);

	if (m_allocator.arena_base != old_arena_base)
		update_version();
}

void Arena::update_version() throw ()
{
	unsigned int version = m_version + 1;

	if (version == 0)
		version = 1;

	m_version = version;
}

Arena::Accession Arena::access(unsigned int address, size_t minimum_size)
{
	check_access_error();
	auto accession = nonthrowing_access(address, minimum_size);
	check_access_error();

	return accession;
}

Arena::Accession Arena::nonthrowing_access(unsigned int address, size_t minimum_size) throw ()
{
	if (address < sizeof (Header)) {
		Trace("address %1% access (minimum size %2%)", address, minimum_size);
		return defer_access_error(address);
	}

#ifndef NDEBUG
	if (address & (sizeof (uint32_t) - 1)) {
		Trace("address %1% alignment error", address);
		return defer_access_error(address);
	}
#endif

	size_t arena_size = m_allocator.arena_size;

	if (arena_size < minimum_size || address > arena_size - minimum_size) {
		Trace("address %1% minimum size %2% out of range", address, minimum_size);
		return defer_access_error(address);
	}

	void *data = reinterpret_cast<char *> (m_allocator.arena_base) + address;

	size_t data_size = AllocationSize(data);
	size_t aligned_size = Allocator::AlignedSize(data_size);

	if (aligned_size < data_size)
		return defer_access_error(address);

	if (arena_size < aligned_size || address > arena_size - aligned_size) {
		Trace("address %1% actual size %2% out of range", address, minimum_size);
		return defer_access_error(address);
	}

	return Accession(m_version, data);
}

Arena::Accession Arena::defer_access_error(unsigned int address) throw ()
{
	if (m_access_error_address == 0) {
		Backtrace();
		m_access_error_address = address;
	}

	return Accession();
}

void Arena::check_access_error()
{
	if (m_access_error_address) {
		auto address = m_access_error_address;
		m_access_error_address = 0;

		throw IntegrityError(address);
	}
}

AllocationError::AllocationError(size_t size) throw ():
	m_size(size)
{
	Backtrace();
}

const char *AllocationError::what() const throw ()
{
	return "Out of memory";
}

IntegrityError::IntegrityError(unsigned int address) throw ():
	m_address(address)
{
	Backtrace();
}

const char *IntegrityError::what() const throw ()
{
	return "Arena integrity violation";
}

} // namespace
